<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lecture 3: Understanding Performance - Lectures on Computer Architecture</title>
    <link rel="stylesheet" href="../../assets/css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    <!-- Prism.js for code syntax highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
</head>
<body>
    <header class="lecture-header">
        <div class="container">
            <a href="../../index.html" class="back-link">
                <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <line x1="19" y1="12" x2="5" y2="12"></line>
                    <polyline points="12 19 5 12 12 5"></polyline>
                </svg>
                Back to All Lectures
            </a>
            <h1 class="lecture-title">Lecture 3: Understanding Performance</h1>
            <p class="lecture-meta">Lectures on Computer Architecture</p>
        </div>
    </header>

    <main class="lecture-content-area container">
        <div class="content-body">
            <!-- Video Section -->
            <div class="video-container">
                <div class="video-thumbnail">
                    <a href="https://www.youtube.com/watch?v=nhwsAOEidik" target="_blank" class="video-play-overlay">
                        <img src="https://img.youtube.com/vi/nhwsAOEidik/maxresdefault.jpg" 
                             alt="Lecture 3 Video Thumbnail"
                             onerror="this.src='https://img.youtube.com/vi/nhwsAOEidik/hqdefault.jpg'">
                        <div class="play-button">
                            <svg width="68" height="48" viewBox="0 0 68 48" fill="none">
                                <path d="M66.52 7.74c-.78-2.93-2.49-5.41-5.42-6.19C55.79.13 34 0 34 0S12.21.13 6.9 1.55c-2.93.78-4.63 3.26-5.42 6.19C.06 13.05 0 24 0 24s.06 10.95 1.48 16.26c.78 2.93 2.49 5.41 5.42 6.19C12.21 47.87 34 48 34 48s21.79-.13 27.1-1.55c2.93-.78 4.64-3.26 5.42-6.19C67.94 34.95 68 24 68 24s-.06-10.95-1.48-16.26z" fill="red"/>
                                <path d="M45 24L27 14v20" fill="white"/>
                            </svg>
                        </div>
                    </a>
                </div>
                <div class="video-info">
                    <p class="video-notice">
                        <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"></circle>
                            <line x1="12" y1="16" x2="12" y2="12"></line>
                            <line x1="12" y1="8" x2="12.01" y2="8"></line>
                        </svg>
                        Click the thumbnail above to watch the video lecture on YouTube
                    </p>
                </div>
            </div>

            
<em>By Dr. Isuru Nawinne</em>

<h2>3.1 Introduction</h2>

<p>Understanding computer performance is fundamental to computer architecture and system design. This lecture explores how performance is measured, the factors that influence it, and the principles that guide performance optimization. We examine the metrics used to evaluate systems, the mathematical relationships between performance factors, and Amdahl's Law—a critical principle for understanding the limits of performance improvements.</p>


<h2>3.2 Defining and Measuring Performance</h2>

<h3>3.2.1 Response Time vs. Throughput</h3>

<p><strong>Response Time (Execution Time)</strong></p>

<ul>
<li>Time to complete a single task</li>
<li>Includes all overhead and waiting time</li>
<li>User-perceived performance metric</li>
<li>Example: Time for a program to run from start to finish</li>
</ul>

<p><strong>Throughput (Bandwidth)</strong></p>

<ul>
<li>Number of tasks completed per unit time</li>
<li>Measures system capacity</li>
<li>Important for servers and data centers</li>
<li>Example: Number of transactions processed per second</li>
</ul>

<p><strong>Relationship Between Metrics</strong></p>

<ul>
<li>Improving response time often improves throughput</li>
<li>Improving throughput doesn't always improve response time</li>
<li>Different optimization strategies for each metric</li>
<li>System design must balance both considerations</li>
</ul>

<h3>3.2.2 Performance Definition</h3>

<p><strong>Mathematical Definition</strong></p>

<div class="math-block">
$$
\text{Performance} = \frac{1}{\text{Execution Time}}
$$
</div>

<p><strong>Performance Comparison</strong></p>

<ul>
<li>If System A is faster than System B:
    <ul>
        <li>Execution Time<sub>A</sub> &lt; Execution Time<sub>B</sub></li>
        <li>Performance<sub>A</sub> &gt; Performance<sub>B</sub></li>
    </ul>
</li>
</ul>

<p><strong>Relative Performance</strong></p>

<div class="math-block">
$$
\frac{\text{Performance}_A}{\text{Performance}_B} = \frac{\text{Execution Time}_B}{\text{Execution Time}_A}
$$
</div>

<p>Example: If System A is 2× faster than System B:</p>

<ul>
<li>Performance<sub>A</sub> / Performance<sub>B</sub> = 2</li>
<li>Execution Time<sub>B</sub> / Execution Time<sub>A</sub> = 2</li>
<li>System A takes half the time of System B</li>
</ul>

<h2>3.3 CPU Time and Performance Factors</h2>

<h3>3.3.1 Components of Execution Time</h3>

<p><strong>Total Execution Time</strong></p>

<ul>
<li>CPU time: Time CPU spends computing the task</li>
<li>I/O time: Time waiting for input/output operations</li>
<li>Other system activities: OS overhead, other programs</li>
</ul>

<p><strong>CPU Time Focus</strong></p>

<ul>
<li>Primary metric for processor performance</li>
<li>Excludes I/O and system effects</li>
<li>Directly reflects processor and memory system performance</li>
<li>Most relevant for comparing processor architectures</li>
</ul>

<h3>3.3.2 The CPU Time Equation</h3>

<p><strong>Basic Formula</strong></p>

<div class="math-block">
$$
\text{CPU Time} = \text{Clock Cycles} \times \text{Clock Period}
$$
</div>

<p>Or equivalently:</p>

<div class="math-block">
$$
\text{CPU Time} = \frac{\text{Clock Cycles}}{\text{Clock Rate}}
$$
</div>

<p><strong>Key Relationships</strong></p>

<ul>
<li>Clock Period = 1 / Clock Rate</li>
<li>Clock Rate measured in Hz (cycles/second)</li>
<li>Clock Cycles = total cycles to execute program</li>
<li>Higher clock rate → shorter clock period → faster execution</li>
</ul>

<p><strong>Example Calculation</strong></p>

<p>Program requires 10 billion cycles<br>
Processor runs at 4 GHz (4 × 10<sup>9</sup> Hz)</p>

<div class="math-block">
$$
\begin{align*}
\text{CPU Time} &= \frac{10 \times 10^9 \text{ cycles}}{4 \times 10^9 \text{ cycles/sec}} \\
&= 2.5 \text{ seconds}
\end{align*}
$$
</div>

<h3>3.3.3 Instruction Count and CPI</h3>

<p><strong>Cycles Per Instruction (CPI)</strong></p>

<ul>
<li>Average number of clock cycles per instruction</li>
<li>Varies by instruction type and implementation</li>
<li>Key microarchitecture metric</li>
</ul>

<p><strong>Extended CPU Time Equation</strong></p>

<div class="math-block">
$$
\text{CPU Time} = \text{Instruction Count} \times \text{CPI} \times \text{Clock Period}
$$
</div>

<p>Or:</p>

<div class="math-block">
$$
\text{CPU Time} = \frac{\text{Instruction Count} \times \text{CPI}}{\text{Clock Rate}}
$$
</div>

<p><strong>Three Performance Factors</strong></p>

<ol>
<li><strong>Instruction Count</strong>: Number of instructions executed</li>
<li><strong>CPI</strong>: Average cycles per instruction</li>
<li><strong>Clock Rate</strong>: Speed of the processor clock</li>
</ol>

<p><strong>Factor Dependencies</strong></p>

<ul>
<li>Instruction Count: Determined by algorithm, compiler, ISA</li>
<li>CPI: Determined by processor implementation (microarchitecture)</li>
<li>Clock Rate: Determined by hardware technology and organization</li>
</ul>

<h2>3.4 Understanding CPI in Detail</h2>

<h3>3.4.1 CPI Variability</h3>

<p><strong>Different Instructions, Different CPIs</strong></p>

<ul>
<li>Simple operations: May complete in 1 cycle (ADD, AND)</li>
<li>Memory operations: May take multiple cycles (LOAD, STORE)</li>
<li>Branch instructions: Variable cycles (depends on prediction)</li>
<li>Multiply/Divide: Often take many cycles</li>
</ul>

<p><strong>Calculating Average CPI</strong></p>

<div class="math-block">
$$
\text{Average CPI} = \frac{\sum (\text{CPI}_i \times \text{Instruction Count}_i)}{\text{Total Instruction Count}}
$$
</div>

<p>Where:</p>

<ul>
<li>CPI<sub>i</sub> = cycles per instruction for instruction type i</li>
<li>Instruction Count<sub>i</sub> = number of times instruction i executed</li>
</ul>

<h3>3.4.2 CPI Example Calculation</h3>

<p><strong>Given:</strong></p>

<ul>
<li>Program executes 100,000 instructions</li>
<li>50,000 ALU operations (CPI = 1)</li>
<li>30,000 load instructions (CPI = 3)</li>
<li>20,000 branch instructions (CPI = 2)</li>
</ul>

<p><strong>Calculation:</strong></p>

<div class="math-block">
$$
\begin{align*}
\text{Total Cycles} &= (50{,}000 \times 1) + (30{,}000 \times 3) + (20{,}000 \times 2) \\
&= 50{,}000 + 90{,}000 + 40{,}000 \\
&= 180{,}000 \text{ cycles}
\end{align*}
$$
</div>

<div class="math-block">
$$
\text{Average CPI} = \frac{180{,}000}{100{,}000} = 1.8
$$
</div>

<h3>3.4.3 Instruction Classes</h3>

<p><strong>Common Instruction Categories</strong></p>

<ol>
<li><strong>Integer arithmetic</strong>: ADD, SUB, AND, OR</li>
<li><strong>Data transfer</strong>: LOAD, STORE</li>
<li><strong>Control flow</strong>: BRANCH, JUMP, CALL</li>
<li><strong>Floating-point</strong>: FADD, FMUL, FDIV</li>
</ol>

<p><strong>CPI Characteristics by Class</strong></p>

<ul>
<li>Integer arithmetic: Usually 1 cycle</li>
<li>Data transfer: 1-3 cycles (cache hit) or more (cache miss)</li>
<li>Control flow: 1-2 cycles (correct prediction) or more (misprediction)</li>
<li>Floating-point: 2-20+ cycles depending on operation</li>
</ul>

<h2>3.5 Performance Optimization Principles</h2>

<h3>3.5.1 Make the Common Case Fast</h3>

<p><strong>Core Principle</strong></p>

<ul>
<li>Optimize frequent operations rather than rare ones</li>
<li>Greater impact on overall performance</li>
<li>Focus resources where they matter most</li>
</ul>

<p><strong>Examples</strong></p>

<ul>
<li>Optimize ALU operations (common) over division (rare)</li>
<li>Fast cache for recent data (commonly accessed)</li>
<li>Branch prediction for likely paths</li>
<li>Simple instructions execute quickly</li>
</ul>

<p><strong>Application in Design</strong></p>

<ul>
<li>Identify common operations through profiling</li>
<li>Allocate hardware resources accordingly</li>
<li>Accept slower performance for rare cases</li>
<li>Trade-offs guided by usage patterns</li>
</ul>

<h3>3.5.2 Amdahl's Law</h3>

<p><strong>The Fundamental Principle</strong></p>
<p>The speedup that can be achieved by improving a particular part of a system is limited by the fraction of time that part is used.</p>

<p><strong>Mathematical Formula</strong></p>

<div class="math-block">
$$
\text{Speedup}_{\text{overall}} = \frac{1}{(1 - P) + \frac{P}{S}}
$$
</div>

<p>Where:</p>

<ul>
<li>P = Proportion of execution time that can be improved</li>
<li>S = Speedup of the improved portion</li>
<li>(1 - P) = Proportion that cannot be improved</li>
</ul>

<p><strong>Alternative Formulation</strong></p>

<div class="math-block">
$$
\text{Execution Time}_{\text{new}} = \text{Execution Time}_{\text{old}} \times \left[(1 - P) + \frac{P}{S}\right]
$$
</div>

<h3>3.5.3 Amdahl's Law Examples</h3>

<p><strong>Example 1: Multiply Operation Speedup</strong></p>

<p>Given:</p>

<ul>
<li>Multiply operations take 80% of execution time</li>
<li>New hardware makes multiplies 10× faster</li>
</ul>

<p>Calculation:</p>


<p>P = 0.80 (80% can be improved)</p>
<p>S = 10 (10× speedup)</p>

<p>Speedup_overall = 1 / [(1 - 0.80) + (0.80 / 10)]</p>
<p>= 1 / [0.20 + 0.08]</p>
<p>= 1 / 0.28</p>
<p>= 3.57×</p>


<strong>Key Insight:</strong> Despite 10× improvement in multiplies, overall speedup is only 3.57× because 20% of time is unaffected.

<p><strong>Example 2: Limited Improvement Fraction</strong></p>

<p>Given:</p>

<ul>
<li>Only 30% of execution can be improved</li>
<li>Improvement is 100× faster</li>
</ul>

<p>Calculation:</p>


<p>P = 0.30</p>
<p>S = 100</p>

<p>Speedup_overall = 1 / [(1 - 0.30) + (0.30 / 100)]</p>
<p>= 1 / [0.70 + 0.003]</p>
<p>= 1 / 0.703</p>
<p>= 1.42×</p>


<strong>Key Insight:</strong> Even with 100× improvement, overall speedup is only 1.42× because only 30% of execution benefits.

<h3>3.5.4 Implications of Amdahl's Law</h3>

<p><strong>Limitations of Parallelization</strong></p>

<ul>
<li>Serial portions limit parallel speedup</li>
<li>As parallelism increases, serial portion dominates</li>
<li>Cannot achieve infinite speedup regardless of cores</li>
</ul>

<p><strong>Optimization Strategy</strong></p>

<ul>
<li>Focus on largest contributors to execution time</li>
<li>Consider what fraction can realistically be improved</li>
<li>Multiple small improvements may beat one large improvement</li>
<li>Balance improvements across components</li>
</ul>

<p><strong>Example: Multicore Scaling</strong></p>

<p>If 90% of program parallelizes perfectly:</p>

<table>
<thead>
<tr>
<th>Cores</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>2 cores</td>
<td>1.82×</td>
</tr>
<tr>
<td>4 cores</td>
<td>3.08×</td>
</tr>
<tr>
<td>8 cores</td>
<td>4.71×</td>
</tr>
<tr>
<td>16 cores</td>
<td>6.40×</td>
</tr>
<tr>
<td>∞ cores</td>
<td>10.00× (maximum possible)</td>
</tr>
</tbody>
</table>

<p>The 10% serial portion ultimately limits speedup to 10×.</p>

<h2>3.6 Complete Performance Analysis</h2>

<h3>3.6.1 The Complete Performance Equation</h3>

<p><strong>Bringing It All Together</strong></p>

<div class="math-block">
$$
\text{CPU Time} = \text{Instruction Count} \times \text{CPI} \times \text{Clock Period}
$$
</div>

<p>Expanded:</p>

<div class="math-block">
$$
\text{CPU Time} = (\text{Instructions}) \times \left(\frac{\text{Cycles}}{\text{Instruction}}\right) \times \left(\frac{\text{Seconds}}{\text{Cycle}}\right)
$$
</div>

<p><strong>What Affects Each Factor</strong></p>

<p><strong>Instruction Count:</strong></p>

<ul>
<li>Algorithm: Efficient algorithms execute fewer instructions</li>
<li>Programming language: High-level vs low-level</li>
<li>Compiler: Optimization quality</li>
<li>ISA: Instruction complexity and capabilities</li>
</ul>

<p><strong>CPI:</strong></p>

<ul>
<li>ISA: Instruction complexity</li>
<li>Microarchitecture: Pipeline depth, branch prediction</li>
<li>Cache performance: Hit rates affect memory access CPI</li>
<li>Instruction mix: Distribution of instruction types</li>
</ul>

<p><strong>Clock Period (or Clock Rate):</strong></p>

<ul>
<li>Technology: Transistor speed (nm process)</li>
<li>Organization: Pipeline depth, critical path length</li>
<li>Power constraints: Higher frequency requires more power</li>
<li>Cooling limitations: Heat dissipation capacity</li>
</ul>

<h3>3.6.2 Performance Comparison Example</h3>

<p><strong>Scenario:</strong></p>
<p>Compare two implementations of the same ISA</p>

<ul>
<li>System A: Clock Rate = 2 GHz, CPI = 2.0</li>
<li>System B: Clock Rate = 3 GHz, CPI = 3.0</li>
<li>Same program with 1 million instructions</li>
</ul>

<p><strong>System A:</strong></p>


<p>CPU Time_A = (1 × 10^6 instructions) × (2.0 cycles/instruction) / (2 × 10^9 cycles/sec)</p>
<p>= 2 × 10^6 cycles / (2 × 10^9 cycles/sec)</p>
<p>= 0.001 seconds = 1 millisecond</p>


<p><strong>System B:</strong></p>


<p>CPU Time_B = (1 × 10^6 instructions) × (3.0 cycles/instruction) / (3 × 10^9 cycles/sec)</p>
<p>= 3 × 10^6 cycles / (3 × 10^9 cycles/sec)</p>
<p>= 0.001 seconds = 1 millisecond</p>


<strong>Result:</strong> Both systems have identical performance despite different clock rates and CPIs.

<h3>3.6.3 Trade-offs in Design</h3>

<p><strong>Clock Rate vs. CPI Trade-off</strong></p>

<ul>
<li>Higher clock rate may require deeper pipeline</li>
<li>Deeper pipeline often increases CPI (more stalls)</li>
<li>Must balance frequency gains against CPI losses</li>
</ul>

<p><strong>Instruction Count vs. CPI Trade-off</strong></p>

<ul>
<li>Complex instructions reduce instruction count</li>
<li>But complex instructions may increase CPI</li>
<li>CISC vs RISC architecture debate</li>
</ul>

<p><strong>Power vs. Performance</strong></p>

<ul>
<li>Higher clock rate increases power consumption</li>
<li>Power = Capacitance × Voltage² × Frequency</li>
<li>Mobile systems prioritize power over peak performance</li>
</ul>

<h2>3.7 Practical Performance Considerations</h2>

<h3>3.7.1 Benchmarking</h3>

<p><strong>Purpose of Benchmarks</strong></p>

<ul>
<li>Measure real-world performance</li>
<li>Compare different systems objectively</li>
<li>Standard workloads for reproducibility</li>
</ul>

<p><strong>Types of Benchmarks</strong></p>

<ul>
<li>Synthetic: Artificial programs (e.g., Dhrystone, Whetstone)</li>
<li>Application: Real programs (e.g., SPEC CPU, databases)</li>
<li>Workload: Representative task mixes</li>
</ul>

<p><strong>Benchmark Pitfalls</strong></p>

<ul>
<li>May not represent your workload</li>
<li>Can be optimized for unfairly</li>
<li>Need multiple benchmarks for complete picture</li>
</ul>

<h3>3.7.2 Performance Metrics in Practice</h3>

<p><strong>MIPS (Million Instructions Per Second)</strong></p>

<div class="math-block">
$$
\text{MIPS} = \frac{\text{Instruction Count}}{\text{Execution Time} \times 10^6} = \frac{\text{Clock Rate}}{\text{CPI} \times 10^6}
$$
</div>

<p><strong>Limitations of MIPS:</strong></p>

<ul>
<li>Doesn't account for instruction complexity</li>
<li>Different ISAs have different instruction capabilities</li>
<li>Higher MIPS doesn't guarantee better performance</li>
<li>"Meaningless Indication of Processor Speed"</li>
</ul>

<p><strong>Better Metrics:</strong></p>

<ul>
<li>Execution time for specific workloads</li>
<li>Throughput for server applications</li>
<li>Energy efficiency (performance per watt)</li>
<li>Performance per dollar</li>
</ul>

<h3>3.7.3 Power and Energy Considerations</h3>

<p><strong>Power Wall</strong></p>

<ul>
<li>Cannot increase clock rate indefinitely</li>
<li>Power consumption limits frequency scaling</li>
<li>Led to multi-core era</li>
</ul>

<p><strong>Dynamic Power Equation</strong></p>

<div class="math-block">
$$
\text{Power} = \text{Capacitance} \times \text{Voltage}^2 \times \text{Frequency}
$$
</div>

<p><strong>Energy Equation</strong></p>

<div class="math-block">
$$
\text{Energy} = \text{Power} \times \text{Time}
$$
</div>

<p><strong>Implications:</strong></p>

<ul>
<li>Lowering voltage reduces power dramatically (squared effect)</li>
<li>Higher frequency increases power linearly</li>
<li>Faster execution may save energy overall (less time)</li>
<li>Energy efficiency increasingly important metric</li>
</ul>

<h2>Key Takeaways</h2>

<ol>
<li><strong>Performance is the inverse of execution time</strong> - faster systems have shorter execution times and higher performance values.</li>

<li><strong>Three key factors determine CPU performance:</strong>
<ul>
<li>Instruction Count (algorithm, compiler, ISA)</li>
<li>CPI (microarchitecture, instruction mix)</li>
<li>Clock Rate (technology, organization)</li>
</ul>
</li>

<li><strong>Amdahl's Law limits speedup</strong> - the potential speedup from improving any part of a system is limited by how much time that part is used.</li>

<li><strong>"Make the common case fast"</strong> - optimize frequently executed operations for maximum impact on overall performance.</li>

<li><strong>CPI varies by instruction type</strong> - average CPI depends on the mix of instructions and their individual costs.</li>

<li><strong>Trade-offs are fundamental</strong> - improvements in one area (e.g., clock rate) may harm another (e.g., CPI or power consumption).</li>

<li><strong>Benchmarking is essential</strong> - real workloads provide the most meaningful performance measurements.</li>

<li><strong>Power is a critical constraint</strong> - modern performance optimization must consider power and energy efficiency, not just speed.</li>

<li><strong>Multiple factors must be optimized together</strong> - focusing on only one aspect (like clock rate) can be counterproductive.</li>

<li><strong>Understanding performance equations</strong> enables rational design decisions and accurate performance predictions.</li>
</ol>

<h2>Summary</h2>

<p>Performance analysis is central to computer architecture, providing the foundation for making informed design decisions. By understanding the relationship between instruction count, CPI, and clock rate, architects can identify optimization opportunities and predict the impact of changes. Amdahl's Law reminds us that the benefit of any improvement is constrained by what fraction of execution time it affects, emphasizing the importance of focusing on the common case. As we design systems, we must balance competing factors—clock rate, CPI, power consumption, and cost—to achieve the best overall performance for target applications. The principles covered in this lecture provide the analytical framework for evaluating processor designs and optimization strategies throughout the study of computer architecture.</p>

            
            <div class="lecture-nav">
                <a href="lecture-02.html" class="nav-btn">← Previous Lecture</a>
                <a href="lecture-04.html" class="nav-btn">Next Lecture →</a>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 CO224 Computer Architecture Lecture Series. All rights reserved.</p>
            <p>Department of Computer Engineering, University of Peradeniya</p>
        </div>
    </footer>
</body>
</html>

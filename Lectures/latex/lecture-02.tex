\section{Lecture 2: Technology Trends, Moore's Law, and Computer System Organization}

\emph{By Dr. Isuru Nawinne}

\subsection{Introduction}

The evolution of computer technology over the past 50 years has been nothing short of revolutionary. From room-sized scientific calculators to powerful smartphones in our pockets, this transformation has been guided by a prediction made by Intel co-founder Gordon Moore. This lecture examines the technological trends that enabled this revolution, the physical limitations that eventually constrained traditional scaling approaches, and the architectural innovations that emerged in response.

We will trace the exponential growth in transistor density, explore how smaller feature sizes enabled both more complex circuits and faster operation, understand why clock frequencies stopped increasing around 2004, and see how the industry pivoted to multi-core architectures. Finally, we'll examine how computer systems are organized into three layers (hardware, system software, and application software) and follow the complete translation process from high-level code to binary execution.

\subsection{Moore's Law - Foundation of Computer Technology Evolution}

\subsubsection{Who Was Gordon Moore?}

\textbf{Background and Influence:}

\begin{itemize}
\item Co-founder of Intel Corporation, historically the biggest manufacturer of computer chips/processors
\item Most personal computers and high-end servers use Intel processors
\item Made a prediction that shaped the entire semiconductor industry
\end{itemize}

\textbf{Intel's Dominance:}

\begin{itemize}
\item Established industry standards for processor design
\item Set pace for computational advancement
\item Influenced competing manufacturers
\item Created benchmark for technology expectations
\end{itemize}

\subsubsection{Moore's Law Definition}

\textbf{The Prediction:}

Moore's Law is NOT a physical law like the law of gravity. It is an observation and prediction about technology trends:

\textbf{"The number of transistors that can be placed on a standard computer chip will double every two years."}

\textbf{Practical Interpretation:}

\begin{itemize}
\item Roughly translates to: Computational power doubles every two years
\item Started in the 1950s and held true for many decades
\item Based on continuous demand for increasing computational power
\item Self-fulfilling prophecy driven by industry investment
\end{itemize}

\textbf{Historical Context:}

\begin{itemize}
\item Initial observation made in mid-1960s
\item Revised and refined over subsequent decades
\item Became guiding principle for semiconductor industry
\item Influenced research priorities and manufacturing investments
\end{itemize}

\subsubsection{Impact of Moore's Law}

\textbf{Computer Evolution Enabled:}

Computers transformed from room-sized scientific calculators to:

\begin{itemize}
\item \textbf{Personal Computers:} Desktop and laptop systems in every home
\item \textbf{Mobile Devices:} Smartphones with computational power exceeding 1990s supercomputers
\item \textbf{Embedded Systems:} Computational intelligence in everyday objects
\item \textbf{Wearables:} Smartwatches and fitness trackers
\end{itemize}

\textbf{Revolutionary Applications:}

Moore's Law made computationally intensive applications possible:

\begin{enumerate}
\item \textbf{Human Genome Decoding:}
\end{enumerate}

\begin{itemize}
\item Massive computational requirements
\item Processing billions of genetic sequences
\item Pattern recognition across enormous datasets
\end{itemize}

\begin{enumerate}
\item \textbf{World Wide Web and Internet Search:}
\end{enumerate}

\begin{itemize}
\item Millisecond response times for complex queries
\item Indexing billions of web pages
\item Real-time information retrieval
\end{itemize}

\begin{enumerate}
\item \textbf{Artificial Intelligence and Machine Learning:}
\end{enumerate}

\begin{itemize}
\item Neural networks with billions of parameters
\item Real-time image and speech recognition
\item Autonomous systems and decision-making
\end{itemize}

\begin{enumerate}
\item \textbf{Complex Simulations and Scientific Computing:}
\end{enumerate}

\begin{itemize}
\item Weather prediction and climate modeling
\item Molecular dynamics simulations
\item Astrophysical calculations
\end{itemize}

\textbf{Societal Impact:}

\begin{itemize}
\item Computer software became ubiquitous and unavoidable
\item Changed how we work, communicate, and learn
\item Enabled digital transformation of industries
\item Created new fields and destroyed old ones
\end{itemize}

\subsection{Technology Scaling - Historical Data}

\subsubsection{Transistor Count Growth (1970-2010)}

\textbf{Chart Analysis:}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{img/Chapter 1 Moore's Law.jpg}
\caption{Moore's Law: Transistor Count Growth}
\end{figure}

The historical data shows remarkable consistency with Moore's prediction:

\begin{itemize}
\item \textbf{Vertical Axis:} Number of transistors (10⁵ to 10⁹ - millions to billions)
\item \textbf{Horizontal Axis:} Time period (1970 to 2010)
\item \textbf{Blue Dotted Line:} Doubling every 18 months (aggressive prediction)
\item \textbf{Red-Brown Line:} Doubling every 24 months (Moore's actual prediction)
\end{itemize}

\textbf{Real Intel Processor Models:}

Tracking actual transistor counts across processor generations:

\begin{itemize}
\item \textbf{Early Processors:} 4004, 8008, 8080 (thousands of transistors)
\item \textbf{1989 Milestone - 8086:} Crossed 1 million transistors
\item \textbf{Middle Era:} Pentium and Itanium series
\item \textbf{2008 Achievement:} Crossed 1 billion transistors (quad-core processors)
\item \textbf{Trend Validation:} Actual counts closely followed the "doubling per 2 years" curve
\end{itemize}

\textbf{Significance:}

\begin{itemize}
\item Prediction held remarkably accurate for 40+ years
\item Enabled long-term planning for semiconductor industry
\item Guided investment in manufacturing technology
\item Set performance expectations for consumers
\end{itemize}

\subsubsection{The x86 Architecture}

\textbf{Origin and Naming:}

\begin{itemize}
\item \textbf{8086 Processor:} First x86 architecture processor (notice "86" in the name)
\item Established instruction set architecture (ISA) standard
\item Created foundation for backward compatibility
\end{itemize}

\textbf{x86 Architecture Family:}

The architecture evolved through multiple generations while maintaining compatibility:

\begin{itemize}
\item \textbf{80286:} Enhanced memory management
\item \textbf{80386:} True 32-bit processor (author's first computer in 1993, 16 MHz)
\item \textbf{80486:} Integrated floating-point unit
\item \textbf{Pentium Series:} Brand name change, performance leap
\item \textbf{Modern Processors:} Core i3, i5, i7, i9 series
\end{itemize}

\textbf{AMD's Adoption:}

\begin{itemize}
\item AMD also uses x86 architecture
\item Compatible instruction set
\item Competitive alternative to Intel
\item Drives innovation through competition
\end{itemize}

\textbf{Evolution Strategy:}

\begin{itemize}
\item Architecture evolved significantly over decades
\item Maintained backward compatibility throughout
\item Old programs run on new processors
\item Balanced innovation with stability
\end{itemize}

\subsubsection{Historical Context}

\textbf{Early Computing Era (1985-1990):}

\begin{itemize}
\item 1985: 80386 computers first arrived on market
\item No graphical user interfaces (GUIs) existed
\item Black screen with text-only displays
\item DOS operating system (text-based console)
\item Command-line interaction only
\end{itemize}

\textbf{Transformation Period (Mid-Late 1990s):}

\begin{itemize}
\item GUIs emerged (Windows 95 and similar systems)
\item Point-and-click interfaces replaced command lines
\item Multimedia capabilities became standard
\item Internet connectivity became widespread
\end{itemize}

\textbf{User Experience Revolution:}

\begin{itemize}
\item Significant transformation in how people interacted with computers
\item Democratized computing beyond technical experts
\item Enabled productivity for non-technical users
\item Set expectations for modern computing
\end{itemize}

\subsection{Feature Size Scaling - Lithography Improvements}

\subsubsection{What Made Transistor Count Increase Possible?}

\textbf{The Answer: Smaller Transistors}

The exponential growth in transistor count was enabled primarily by reducing transistor size through improved manufacturing processes.

\textbf{Lithography Process:}

\begin{itemize}
\item Etching transistors onto silicon wafer using photolithographic techniques
\item Patterns created using light masks and photosensitive materials
\item Feature size: Measure of transistor dimensions in nanometers (nm)
\item Smaller features = more transistors per unit area
\end{itemize}

\textbf{Feature Size Timeline:}

The relentless march toward smaller dimensions:

\begin{itemize}
\item \textbf{2004:} 90 nanometer manufacturing process
\item \textbf{2006:} 65 nanometer
\item \textbf{2008:} 45 nanometer (very famous generation, many developments)
\item \textbf{Continuing:} 32 nm, 22 nm processes
\item \textbf{2013 Actual:} 22 nm achieved
\item \textbf{2015 Target:} 16 nm achieved
\item \textbf{2019 Target:} 12 nm achieved
\item \textbf{2023 Target:} 7 nm achieved
\item \textbf{2028 Target:} 5 nm exceeded
\item \textbf{Future Roadmap:} 3nm and 2nm are currently in production, future is 1nm and sub-1nm
\end{itemize}

\subsubsection{What is "Feature Size"?}

\textbf{Original Definition:}

\begin{itemize}
\item Originally represented physical measurement: minimum distance between source and drain of transistor
\item Also called channel width, gate size, or half-pitch
\item Directly related to transistor dimensions
\end{itemize}

\textbf{Modern Reality:}

\begin{itemize}
\item \textbf{NOT a precisely defined physical measurement anymore}
\item More of a \textbf{marketing term} in current usage
\item General measure of manufacturing process advancement
\item Smaller number suggests more advanced technology
\end{itemize}

\textbf{Alternative Names:}

Different terms referring to approximately the same concept:

\begin{itemize}
\item Gate size
\item Channel width
\item Half-pitch
\item Process node
\item Technology node
\end{itemize}

\textbf{Why Ambiguity Developed:}

\begin{itemize}
\item Manufacturing processes became more complex
\item Multiple dimensions define transistor performance
\item 3D structures don't have simple linear measurements
\item Marketing convenience over physical precision
\end{itemize}

\subsubsection{How Tiny Are Transistors?}

\textbf{Mind-Boggling Scale:}

Putting modern transistor sizes in perspective:

\begin{itemize}
\item \textbf{45 nanometer technology:} Can fit \textbf{30 million transistors} on the head of a pin
\item \textbf{Across human hair:} Over \textbf{1,000 transistors} fit across the width of a single human hair
\item \textbf{Comparison to past:} Incredibly small compared to transistors 40-50 years ago
\end{itemize}

\textbf{Manufacturing Precision:}

\begin{itemize}
\item Requires cleanroom environments cleaner than surgical suites
\item Dust particle can destroy multiple chips
\item Atomic-level precision required
\item Remarkable engineering achievement
\end{itemize}

\subsubsection{Transistor Structure}

\textbf{Basic Components:}

\begin{itemize}
\item \textbf{Silicon Substrate:} Base semiconductor material
\item \textbf{Source and Drain:} Two metal contacts on either side
\item \textbf{Gate:} Control electrode positioned between source and drain
\item \textbf{Insulator:} Separates gate from channel
\end{itemize}

\textbf{Feature Size Definition:}

\begin{itemize}
\item Distance between drain and source (channel width)
\item Critical dimension for transistor operation
\item Determines electrical characteristics
\end{itemize}

\textbf{Electrical Properties:}

\begin{itemize}
\item \textbf{Capacitance Load:} Inherent property based on semiconductor material and structure
\item Affects switching speed and power consumption
\item Function of transistor geometry and materials
\item Critical parameter for circuit performance
\end{itemize}

\subsection{Technology Roadmaps - ITRS Predictions}

\subsubsection{ITRS Organization}

\textbf{International Technology Roadmap for Semiconductors:}

\begin{itemize}
\item \textbf{Established:} Around 2001
\item \textbf{Purpose:} Predict feature size scaling for next 10 years
\item \textbf{Membership:} Major semiconductor manufacturers and research institutions
\item \textbf{Methodology:} Based on technology capabilities and market demand
\end{itemize}

\textbf{Prediction Basis:}

The roadmaps considered multiple factors:

\begin{itemize}
\item Demand for computational power
\item Available manufacturing technology
\item Potential technological improvements
\item Economic feasibility
\item Physical limitations
\end{itemize}

\textbf{Regular Updates:}

\begin{itemize}
\item Produced updated roadmaps regularly
\item Adjusted predictions based on actual progress
\item Guided industry research priorities
\item Dissolved in 2015 due to paradigm shift
\end{itemize}

\subsubsection{Original Roadmap (2001)}

\textbf{Optimistic Projections:}

The initial roadmap predicted steady exponential decrease in feature size:

\begin{itemize}
\item \textbf{2001 Baseline:} 130 nm technology in production
\item \textbf{2006 Target:} 65 nm
\item \textbf{2008 Target:} 45 nm
\item \textbf{2012 Projection:} Continuing decrease following Moore's Law
\end{itemize}

\textbf{Assumptions:}

\begin{itemize}
\item Linear continuation of historical trends
\item Traditional planar transistor scaling
\item Continued improvements in lithography
\item Economic sustainability of smaller features
\end{itemize}

\subsubsection{Revised Roadmap (2013)}

\textbf{Adjusted Expectations:}

By 2013, reality required revised predictions:

\begin{itemize}
\item \textbf{2013 Actual:} 22 nm achieved
\item \textbf{2015 Target:} 16 nm predicted
\item \textbf{2019 Target:} 12 nm
\item \textbf{2023 Target:} 7 nm
\item \textbf{2028 Target:} 5 nm
\end{itemize}

\textbf{Key Observations:}

\begin{itemize}
\item \textbf{Rate of reduction slowed down} compared to original predictions
\item Still following exponential trend but slower pace
\item Physical and economic challenges becoming apparent
\item Need for alternative approaches emerging
\end{itemize}

\subsubsection{Final Roadmap (2015)}

\textbf{Dramatic Shift in Direction:}

The 2015 roadmap marked a fundamental change:

\begin{itemize}
\item \textbf{2015 Status:} Still around 25-24 nm (behind 2013 predictions)
\item \textbf{Near-term Projection:} Fast improvements predicted to reach 10 nm
\item \textbf{2021 Target:} 10 nm technology
\item \textbf{Long-term Direction:} Feature size would \textbf{NOT decrease further beyond 10 nm}
\item \textbf{Plateau:} Would stick with 10 nm for foreseeable future
\end{itemize}

\textbf{Significance:}

\begin{itemize}
\item Sudden departure from decades of continuous scaling
\item Recognition of fundamental physical limits
\item Industry acknowledgment of new paradigm
\item End of traditional Moore's Law scaling
\end{itemize}

\subsubsection{Why the Change? - 3D Technology}

\textbf{Major Paradigm Shift (2013-2015):}

The industry pivoted to a fundamentally different approach:

\textbf{Traditional Approach (Before):}

\begin{itemize}
\item Single layer of transistors on silicon surface
\item Scaling by making transistors smaller
\item Two-dimensional planar structures
\end{itemize}

\textbf{New Approach (After):}

\begin{itemize}
\item \textbf{3D Chips:} Multiple layers of transistors stacked vertically
\item \textbf{3D FinFET Technology:} Transistor fins extending upward from surface
\item \textbf{Vertical Integration:} Third dimension for density increase
\end{itemize}

\textbf{Impact on Moore's Law:}

\begin{itemize}
\item Transistor count \textbf{still increasing} (Moore's Law continues)
\item But \textbf{NOT by making individual transistors smaller}
\item Instead: \textbf{Stacking transistors on top of each other}
\item Adds thickness dimension to chip design
\end{itemize}

\textbf{Technical Innovations:}

\begin{itemize}
\item Gate-all-around (GAA) transistors
\item Through-silicon vias (TSVs) for vertical connections
\item Advanced packaging techniques
\item Thermal management solutions
\end{itemize}

\subsubsection{Dissolution of ITRS (2015)}

\textbf{Reasons for Dissolution:}

\begin{itemize}
\item \textbf{Technology Divergence:} Multiple paths to increase transistor density
\item \textbf{End of Simple Scaling:} No longer just reducing feature size
\item \textbf{3D Stacking:} Fundamentally different approach
\item \textbf{Heterogeneous Integration:} Combining different technologies on same chip
\end{itemize}

\textbf{Multiple Methods for Transistor Density:}

Modern approaches include:

\begin{itemize}
\item 3D stacking of transistor layers
\item FinFET and GAA transistor structures
\item Chiplet architectures
\item Advanced packaging technologies
\item Heterogeneous integration
\end{itemize}

\textbf{Moore's Law Status:}

\begin{itemize}
\item Transistor count \textbf{still doubling every 2 years} (as of 2021)
\item But through \textbf{different means} than traditional scaling
\item More complex and diverse strategies
\item Higher costs per transistor (economic Moore's Law ending)
\end{itemize}

\subsection{Why Smaller Transistors Improve Performance}

\subsubsection{Reason 1: More Complex Circuits}

\textbf{Increased Transistor Budget:}

More transistors available on chip enables more sophisticated functionality.

\textbf{Comparison Example:}

\textbf{Limited Transistor Count (100 transistors):}

\begin{itemize}
\item Can only build simple functional units
\item Complex tasks must be broken down into simple operations
\item Must use simple functional units repeatedly
\item Sequential processing of sub-tasks
\item \textbf{Result: SLOWER overall execution}
\end{itemize}

\textbf{Abundant Transistors (1 billion):}

\begin{itemize}
\item Can build extremely complex circuits
\item Perform complex operations in single step
\item Don't need to decompose into simple operations
\item Dedicated hardware for sophisticated functions
\item \textbf{Result: FASTER overall execution}
\end{itemize}

\textbf{Architectural Implications:}

\begin{itemize}
\item Larger caches for better hit rates
\item More sophisticated branch predictors
\item Wider execution units (SIMD)
\item More parallel functional units
\item Hardware accelerators for specific tasks
\end{itemize}

\subsubsection{Reason 2: Faster Switching}

\textbf{Electrical Advantages of Smaller Size:}

Smaller transistors possess superior electrical characteristics:

\textbf{Lower Operating Voltage:}

\begin{itemize}
\item Smaller channel width requires less voltage to switch transistor
\item Voltage scaling: From ~5V (1980s) to ~1V (modern)
\item Reduces power consumption
\item Enables higher switching frequencies
\end{itemize}

\textbf{Reduced Impedance:}

\begin{itemize}
\item Lower resistance in transistor channel
\item Faster current flow
\item Quicker charging/discharging of capacitances
\end{itemize}

\textbf{Faster State Changes:}

\begin{itemize}
\item Can switch transistor on/off faster
\item Less time needed for signal propagation
\item Shorter gate delays
\end{itemize}

\textbf{Overall Impact:}

\begin{itemize}
\item Faster transistor switching $\rightarrow$ Higher possible clock rate
\item Higher clock rate $\rightarrow$ More operations per second
\item Faster overall computation
\end{itemize}

\textbf{Physical Explanation:}

The relationship between size and speed involves:

\begin{itemize}
\item Reduced gate capacitance (smaller area)
\item Shorter carrier transit time (shorter channel)
\item Lower RC time constants
\item Improved frequency response
\end{itemize}

\subsection{Clock Rate Trends - The Power Wall}

\subsubsection{Clock Rate Increases (1982-2004)}

\textbf{Exponential Growth Era:}

Processor clock frequencies increased dramatically for over two decades:

\textbf{Historical Progression:}
\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{img/Chapter 1 Power Wall.jpg}
\caption{Clock Rate Trends and the Power Wall}
\end{figure}

\begin{itemize}
\item \textbf{286 (1982):} 12.5 MHz
\item \textbf{386 (1985):} 16 MHz (author's first computer)
\item \textbf{486 (Early 1990s):} 25-33 MHz
\item \textbf{Pentium (Mid-1990s):} 60-200 MHz
\item \textbf{Pentium 4 (2001):} 2 GHz (2000 MHz) - \textbf{First to break 2 GHz barrier}
\item \textbf{Pentium 4 Prescott (2004):} 3.6 GHz (3600 MHz) - \textbf{Peak of single-core era}
\end{itemize}

\textbf{Growth Rate:}

\begin{itemize}
\item Nearly 300$\times$ increase in 20 years
\item Roughly doubled every 18-24 months
\item Parallel to Moore's Law for transistor count
\item Consumer expectation of continuous frequency increases
\end{itemize}

\subsubsection{The Turning Point (2004-2007)}

\textbf{Sudden Deceleration:}

Around 2004, the decades-long trend dramatically changed:

\begin{itemize}
\item Clock rate increase \textbf{slowed dramatically}
\item Reached peak around \textbf{3.6-4 GHz}
\item Settled and plateaued at that level
\item \textbf{Despite transistors continuing to get smaller}
\end{itemize}

\textbf{The Paradox:}

\begin{itemize}
\item Manufacturing processes still improving
\item More transistors available
\item Smaller, potentially faster transistors
\item \textbf{But clock frequencies stopped increasing}
\end{itemize}

\textbf{Industry Recognition:}

\begin{itemize}
\item Fundamental limitation encountered
\item Alternative approaches needed
\item Architectural innovation required
\item End of "free" performance scaling
\end{itemize}

\subsubsection{The Power Wall Problem}

**Power Consumption Growth Crisis:

As clock rates increased, power consumption grew unsustainably:

\textbf{Pentium 4 Prescott Example:}

\begin{itemize}
\item Required more than \textbf{100 watts} of power
\item Power supply could provide the necessary electrical power
\item \textbf{But HEAT became the critical limiting issue}
\end{itemize}

\textbf{The Thermal Crisis:}

Physical reality of heat generation:

\begin{enumerate}
\item \textbf{Heat Generation Mechanism:}
\end{enumerate}

\begin{itemize}
\item Billions of transistors switching billions of times per second
\item Each switching event involves current flow
\item Current through resistance generates heat (I²R losses)
\item Accumulated heat from all transistors
\end{itemize}

\begin{enumerate}
\item \textbf{Heat Dissipation Challenge:}
\end{enumerate}

\begin{itemize}
\item Heat generation outpaced heat removal capability
\item Chips would overheat and potentially burn
\item Thermal damage to silicon
\item Reliability concerns and failure modes
\end{itemize}

\textbf{The 100-Watt Rule of Thumb:}

Industry consensus emerged:

\begin{itemize}
\item \textbf{Maximum practical limit: ~100 watts per chip}
\item Cooling solutions couldn't effectively handle more
\item Would not cross that boundary for desktop processors
\item Required alternative approaches to improve performance
\end{itemize}

\textbf{Attempted Solutions (All Insufficient):}

Various cooling methods were tried:

\begin{itemize}
\item \textbf{Improved Air Cooling:}
\end{itemize}

\begin{itemize}
\item Larger heatsinks
\item More powerful fans
\item Better thermal interface materials
\end{itemize}

\begin{itemize}
\item \textbf{Liquid Cooling:}
\end{itemize}

\begin{itemize}
\item Water cooling systems (like car radiators)
\item More efficient heat transfer
\item Complex and expensive
\end{itemize}

\begin{itemize}
\item \textbf{Exotic Solutions:}
\item Phase-change cooling
\item Thermoelectric coolers
\item Ultimately impractical for consumer systems
\end{itemize}

\textbf{None Sufficient:}

\begin{itemize}
\item Couldn't overcome fundamental heat generation problem
\item Cost and complexity prohibitive
\item Reliability concerns
\item Not scalable to mass market
\end{itemize}

\subsubsection{Dynamic Power Equation}

**The Physics of Power Consumption:

Dynamic power consumption follows this relationship:

Power = Capacitance Load $\times$ Voltage² $\times$ Frequency

\textbf{Factor Analysis (1982-2004):}

\textbf{Capacitance Load:}

\begin{itemize}
\item \textbf{Relatively Constant} per transistor
\item Inherent to transistor structure and materials
\item Determined by semiconductor physics
\item Cannot be arbitrarily reduced
\end{itemize}

\textbf{Voltage Reduction:}

\begin{itemize}
\item Decreased from \textbf{~5V to ~1V}
\item \textbf{5$\times$ voltage reduction}
\item Squared effect: \textbf{25$\times$ power reduction} contribution
\item Significant mitigation strategy
\end{itemize}

\textbf{Frequency Increase:}

\begin{itemize}
\item Increased \textbf{~300$\times$ (12 MHz to 3600 MHz)}
\item Direct linear effect on power
\item \textbf{300$\times$ power increase} contribution
\item Overwhelmed voltage reduction benefits
\end{itemize}

\textbf{Net Effect Calculation:}

$$
\begin{align*}
	ext{Power Scaling} \&= (\text{Capacitance}) \times (\text{Voltage}^2) \times (\text{Frequency}) \\
\&= (1\times) \times (\frac{1}{5})^2 \times (300\times) \\
\&= (1\times) \times (\frac{1}{25}) \times (300\times) \\
\&= 12\times \text{ power increase}
\end{align*}
$$

\textbf{Key Insight:}

\begin{itemize}
\item Despite aggressive voltage scaling (25$\times$ reduction in V² term)
\item Frequency increase (300$\times$) overwhelmed the benefit
\item Net result: \textbf{Massive power increase}
\item Power grew faster than could be managed thermally
\item Fundamental limitation reached
\end{itemize}

\textbf{Why Voltage Couldn't Scale Further:}

\begin{itemize}
\item Transistor threshold voltages have physical limits
\item Signal-to-noise ratio requirements
\item Reliability constraints
\item Leakage current increases at lower voltages
\end{itemize}

\subsubsection{Overclocking Phenomenon}

**Marketing and User Community Response:

Emerged prominently around early 2000s during the MHz wars:

\textbf{Manufacturer Approach:}

\begin{itemize}
\item \textbf{"Official" Specifications:} Conservative clock speed (e.g., 3.6 GHz)
\item \textbf{Actual Capability:} Could run at higher speeds without guarantees
\item \textbf{Marketing Tactic:} Appeal to gamers and power users
\item \textbf{Risk Disclaimer:} No warranty at higher speeds
\end{itemize}

\textbf{User Overclocking:}

Users could manually increase clock speed beyond rated specification:

\textbf{Process:}

\begin{itemize}
\item Change BIOS/UEFI settings
\item Increase multiplier or bus speed
\item Often increase voltage
\item Improve cooling solutions
\end{itemize}

\textbf{Risks:}

\begin{itemize}
\item \textbf{Generate More Heat:} Exceed thermal design power (TDP)
\item \textbf{Potential Damage:} Could permanently destroy processor
\item \textbf{Instability:} System crashes and data corruption
\item \textbf{Reduced Lifespan:} Accelerated aging of components
\item \textbf{Voided Warranty:} No manufacturer support
\end{itemize}

\textbf{Target Audience:}

\begin{itemize}
\item \textbf{Gamers:} Seeking maximum frame rates
\item \textbf{Enthusiasts:} Hobbyists and competitors
\item \textbf{Overclockers:} Specialized community
\item \textbf{Benchmarkers:} Competitive performance testing
\end{itemize}

\textbf{Industry Impact:}

\begin{itemize}
\item Created enthusiast market segment
\item Influenced product differentiation (K-series Intel chips)
\item Added revenue from premium products
\item Many processors destroyed but market remained
\end{itemize}

\subsection{Shift to Multi-Core Processors}

\subsubsection{The Challenge}

\textbf{The Industry Dilemma:}

By mid-2000s, the semiconductor industry faced a paradox:

\textbf{Available Resources:}

\begin{itemize}
\item Moore's Law still valid: More transistors available every generation
\item Manufacturing processes continuing to improve
\item Silicon area increasing or transistor density growing
\end{itemize}

\textbf{Constraints:}

\begin{itemize}
\item \textbf{Cannot use all transistors simultaneously} (power wall/heat problem)
\item \textbf{Cannot increase clock rate} (thermal limitations)
\item Traditional performance scaling broken
\end{itemize}

\textbf{Critical Questions:}

\begin{itemize}
\item How to utilize available transistors?
\item How to continue improving computational power?
\item How to maintain Moore's Law performance benefits?
\end{itemize}

\subsubsection{Solution: Multiple Processor Cores}

**Paradigm Shift (2004-2008):

Industry pivoted from single-core to multi-core architectures:

\textbf{Core Concept:}

Instead of one powerful processor, put \textbf{multiple complete processors on same chip}:

\begin{itemize}
\item Each core is a complete CPU
\item Cores share cache and memory interface
\item Can execute different programs simultaneously
\item Parallel execution at thread/process level
\end{itemize}

\textbf{Early Multi-Core Processors:}

\textbf{AMD Barcelona (2007):}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{img/Chapter 1 AMD Barcelona.jpg}
\caption{AMD Barcelona Quad-Core Processor}
\end{figure}

\begin{itemize}
\item \textbf{4 cores} on single die
\item Shared L3 cache
\item Integrated memory controller
\end{itemize}

\textbf{Intel Core Series:}

\begin{itemize}
\item Multiple models with \textbf{4 cores}
\item Hyperthreading technology (2 threads per core)
\item Competitive performance
\end{itemize}

\textbf{IBM Processors:}

\begin{itemize}
\item Server-oriented multi-core designs
\item High core counts for enterprise
\item Power-efficient designs
\end{itemize}

\textbf{Extreme Designs:}

\begin{itemize}
\item Some manufacturers: \textbf{8 cores} per chip
\item Specialized server processors with more
\item Graphics processors (GPUs) with hundreds of simple cores
\end{itemize}

\textbf{Power Management:}

\begin{itemize}
\item \textbf{Dynamic Power Allocation:} Cores powered on/off as needed
\item \textbf{Turbo Boost:} Temporarily increase frequency of active cores
\item \textbf{Per-Core Voltage/Frequency Scaling:} Independent control
\item \textbf{Power Gating:} Completely shut down unused cores
\item \textbf{Thermal Management:} Distribute heat across die
\end{itemize}

\subsubsection{The Plan}

\textbf{Initial Industry Vision:}

Following Moore's Law principle for core counts:

\textbf{Projected Growth:}

\begin{itemize}
\item \textbf{Every 2 years:} Double the number of cores per chip
\item Use increased transistor budget for more cores
\item Each generation: 2$\times$ cores, same power envelope
\end{itemize}

\textbf{Timeline Projection:}

\begin{itemize}
\item \textbf{2006:} 4 cores
\item \textbf{2008:} 8 cores
\item \textbf{2010:} 16 cores
\item \textbf{2012:} 32 cores
\item \textbf{2014:} 64 cores
\item \textbf{By 2021:} Should have \textbf{hundreds of cores} in consumer processors
\end{itemize}

\textbf{Theoretical Benefits:}

\begin{itemize}
\item Continuous performance improvement
\item Utilizing Moore's Law transistor growth
\item Working within power constraints
\item Parallel computing becoming mainstream
\end{itemize}

\textbf{Reality Check:}

\begin{itemize}
\item \textbf{This did NOT happen}
\item Current consumer chips: Typically \textbf{4-16 cores} (2021)
\item Server processors: Up to 64-128 cores
\item Not the hundreds predicted
\item Growth much slower than initial projections
\end{itemize}

\subsubsection{Why Multi-Core Growth Slowed}

\textbf{The Fundamental Problem: Parallel Programming Difficulty}

\textbf{Software Challenge:}

Multi-core processors require fundamentally different programming approach:

\textbf{Sequential Programming (Traditional):}

\begin{itemize}
\item Single thread of execution
\item One operation after another
\item Natural mental model
\item Straightforward debugging
\item Predictable behavior
\end{itemize}

\textbf{Parallel Programming (Required for Multi-Core):}

\begin{itemize}
\item Multiple simultaneous threads of execution
\item Programmer must \textbf{explicitly} write code for multiple processors
\item Must think: "I'm writing for 4, 8, or 16 processors"
\item Coordinate and synchronize multiple processes/threads
\item Manage shared resources and data
\end{itemize}

\textbf{Available Parallel Programming Techniques:}

\textbf{Multi-Threading:}

\begin{itemize}
\item \textbf{POSIX Threads (pthreads)} in C/C++
\item Java threading primitives
\item Python threading/multiprocessing
\item Operating system thread scheduling
\end{itemize}

\textbf{Multiple Processes:}

\begin{itemize}
\item Fork/join models
\item Message passing (MPI for scientific computing)
\item Process pools
\end{itemize}

\textbf{Communication Mechanisms:}

\begin{itemize}
\item Shared memory
\item Message queues
\item Pipes and sockets
\item Synchronization primitives (mutexes, semaphores, barriers)
\end{itemize}

\textbf{Language Support:}

\begin{itemize}
\item Available in most major programming languages
\item Library support varies in quality
\item Language-level primitives vs library-based approaches
\end{itemize}

\textbf{Inherent Difficulties:}

\textbf{1. Parallel Programming is HARD:}

\begin{itemize}
\item Much more difficult than sequential programming
\item Different mental model required
\item Non-deterministic behavior
\item Difficult to reproduce bugs
\item Race conditions and deadlocks
\end{itemize}

\textbf{2. Requires Deep Understanding:}

\begin{itemize}
\item \textbf{Hardware Architecture:} How cores communicate, cache coherency
\item \textbf{Processor Organization:} Memory hierarchy, interconnects
\item \textbf{Communication Overhead:} Cost of data transfer between cores
\item \textbf{Synchronization Overhead:} Cost of coordinating execution
\end{itemize}

\textbf{Key Technical Challenges:}

\textbf{Load Balancing:}

\begin{itemize}
\item \textbf{Problem:} Distribute work evenly across all cores
\item \textbf{Bad Scenario:} One processor idle while another overloaded
\item \textbf{Requirement:} Dynamic or static work distribution
\item \textbf{Complexity:} Workload often unknown until runtime
\item \textbf{Solution Difficulty:} NP-hard problem in general case
\end{itemize}

\textbf{Communication Optimization:}

\begin{itemize}
\item \textbf{Problem:} Minimize data transfer between cores
\item \textbf{Reality:} Communication takes time (overhead)
\item \textbf{Amdahl's Law:} Communication is sequential bottleneck
\item \textbf{Cache Coherency:} Hardware protocol overhead
\item \textbf{Solution:} Locality-aware algorithms, minimize sharing
\end{itemize}

\textbf{Synchronization:}

\begin{itemize}
\item \textbf{Problem:} Coordinate execution between cores
\item \textbf{Bad Scenario:} One thread waiting indefinitely for another
\item \textbf{Overhead:} Synchronization primitives have cost
\item \textbf{Deadlock Risk:} Circular dependencies can halt system
\item \textbf{Solution:} Careful design, lock-free algorithms
\end{itemize}

\textbf{Performance Consequences:}

If parallel programming not done well:

\begin{itemize}
\item \textbf{Wasting Available Hardware:} Cores sitting idle
\item \textbf{No Performance Gain:} Sequential sections dominate
\item \textbf{Worse Performance:} Overhead exceeds benefits
\item \textbf{Unpredictable Results:} Race conditions cause incorrect output
\end{itemize}

\subsubsection{Instruction-Level Parallelism vs Multi-Core Parallelism}

\textbf{Instruction-Level Parallelism (ILP):}

\textbf{Characteristics:}

\begin{itemize}
\item \textbf{Hardware-Based Solution:} Processor automatically finds parallelism
\item \textbf{Automatic Execution:} Fetches multiple instructions simultaneously
\item \textbf{Out-of-Order Execution:} Reorders for efficiency
\item \textbf{Compiler Support:} Helps but not required
\item \textbf{Transparent to Programmer:} No special code needed
\item \textbf{Automatic and Hidden:} Works without programmer awareness
\end{itemize}

\textbf{Techniques:}

\begin{itemize}
\item Superscalar execution
\item Out-of-order execution
\item Register renaming
\item Speculative execution
\item Branch prediction
\end{itemize}

\textbf{Benefits:}

\begin{itemize}
\item Free performance improvement
\item Works on existing sequential code
\item No programmer burden
\item Automatic optimization
\end{itemize}

\textbf{Multi-Core Parallelism:}

\textbf{Characteristics:}

\begin{itemize}
\item \textbf{Explicit Programming Required:} Programmer must manually parallelize
\item \textbf{Not Automatic:} No hardware magic
\item \textbf{Much More Difficult:} Requires expertise
\item \textbf{Programmer Responsibility:} Must handle all coordination
\end{itemize}

\textbf{Programmer Must:}

\begin{itemize}
\item Break program into parallel threads
\item Distribute work across cores
\item Handle inter-core communication
\item Manage synchronization
\item Deal with race conditions
\item Avoid deadlocks
\item Balance load
\item Minimize communication overhead
\end{itemize}

\textbf{Contrast:}

| Aspect        | ILP       | Multi-Core       |
| ------------- | --------- | ---------------- |
| Who does work | Hardware  | Programmer       |
| Transparency  | Invisible | Explicit         |
| Difficulty    | Automatic | Hard             |
| Applicability | All code  | Limited patterns |
| Overhead      | Hidden    | Must manage      |

\subsubsection{Impact on Software Development}

\textbf{For Regular Programmers:}

\begin{itemize}
\item \textbf{Too Difficult:} Most cannot effectively parallelize
\item \textbf{Not Worth Effort:} For many applications
\item \textbf{Sequential Sufficient:} Many programs don't need parallel performance
\item \textbf{Training Gap:} Most programmers not trained in parallel programming
\end{itemize}

\textbf{For Computer Engineers:}

\begin{itemize}
\item \textbf{Essential Skill:} Must learn parallel programming
\item \textbf{Career Requirement:} High-performance computing demands it
\item \textbf{Necessary Understanding:} Must understand hardware deeply
\item \textbf{Specialized Constructs:} Must master threading, synchronization
\item \textbf{Architecture Knowledge:} Must understand cache coherency, memory models
\end{itemize}

\textbf{Application Domains:}

\textbf{High-Performance Applications Requiring Parallelism:}

\begin{itemize}
\item Scientific computing and simulations
\item Video encoding/decoding
\item Machine learning training
\item Real-time graphics rendering
\item Big data processing
\item Financial modeling
\end{itemize}

\textbf{Applications That Remain Sequential:}

\begin{itemize}
\item Many business applications
\item Simple utilities
\item I/O-bound programs
\item Interactive applications
\item Legacy software
\end{itemize}

\textbf{Education Impact:}

\begin{itemize}
\item Computer science curricula adding parallel programming courses
\item Need for hardware architecture understanding
\item Gap between industry needs and graduate preparation
\item Specialized training for HPC (high-performance computing)
\end{itemize}

\subsection{Computer System Organization - Three Layers}

\subsubsection{Hardware Layer (Bottom)}

\textbf{Physical Components:}

\textbf{Processor (CPU):}

\begin{itemize}
\item Central Processing Unit
\item Executes machine instructions
\item Contains control and datapath
\item Includes registers and functional units
\end{itemize}

\textbf{Microarchitecture:}

\begin{itemize}
\item Internal organization of processor
\item Pipeline structure
\item Execution units
\item Cache organization
\item Bus interfaces
\end{itemize}

\textbf{Memory Hierarchy:}

\begin{itemize}
\item \textbf{Level 1 Cache (L1):}
\end{itemize}

\begin{itemize}
\item Smallest, fastest
\item Separate instruction and data caches
\item On-core, immediate access
\item Typically 32-64 KB per core
\end{itemize}

\begin{itemize}
\item \textbf{Level 2 Cache (L2):}
\end{itemize}

\begin{itemize}
\item Larger, slightly slower
\item May be shared or per-core
\item Typically 256 KB - 1 MB per core
\end{itemize}

\begin{itemize}
\item \textbf{Level 3 Cache (L3):}
\end{itemize}

\begin{itemize}
\item Largest, slower than L2
\item Shared across all cores
\item Typically several MB
\end{itemize}

\begin{itemize}
\item \textbf{Main Memory (RAM):}
\item Dynamic RAM (DRAM)
\item Several GB capacity
\item Much slower than cache
\item Volatile storage
\end{itemize}

\textbf{Input/Output Controllers:}

\begin{itemize}
\item USB controllers
\item Network interfaces
\item Display adapters
\item Storage controllers
\end{itemize}

\textbf{Secondary Storage Interfaces:}

\begin{itemize}
\item SATA for hard drives/SSDs
\item NVMe for fast SSDs
\item External storage connections
\end{itemize}

\textbf{Purpose:}

\begin{itemize}
\item Actual physical components that execute computation
\item Store and retrieve data
\item Interact with peripherals and external world
\item Provide computational substrate
\end{itemize}

\subsubsection{System Software Layer (Middle)}

**Tool Chain Components:

\textbf{Compiler:}

\begin{itemize}
\item \textbf{Function:} Translates high-level language to assembly
\item \textbf{Input:} Source code (C, Java, Python, etc.)
\item \textbf{Output:} Assembly language or intermediate representation
\item \textbf{Optimization:} Improves performance, reduces size
\item \textbf{Examples:} GCC, Clang, MSVC, Javac
\end{itemize}

\textbf{Assembler:}

\begin{itemize}
\item \textbf{Function:} Translates assembly to machine code
\item \textbf{Input:} Assembly language (human-readable mnemonics)
\item \textbf{Output:} Object files (binary machine code)
\item \textbf{Tasks:} Symbol resolution, address assignment
\item \textbf{Examples:} GNU Assembler (as), NASM
\end{itemize}

\textbf{Linker:}

\begin{itemize}
\item \textbf{Function:} Combines object files and libraries
\item \textbf{Tasks:} Resolves external references, creates executable
\item \textbf{Output:} Complete executable program
\item \textbf{Link Types:} Static linking, dynamic linking
\item \textbf{Examples:} GNU ld, MSVC linker
\end{itemize}

\textbf{Purpose of Tool Chain:}

\begin{itemize}
\item Support application development
\item Bridge high-level abstractions to machine code
\item Enable programmer productivity
\item Provide optimization opportunities
\end{itemize}

\textbf{Operating System:}

\textbf{Core Responsibilities:}

\textbf{Resource Management:}

\begin{itemize}
\item CPU time allocation
\item Memory space allocation
\item I/O device arbitration
\item Storage space management
\end{itemize}

\textbf{Memory Management:}

\begin{itemize}
\item Virtual memory implementation
\item Page tables and address translation
\item Memory protection between processes
\item Swap space management
\end{itemize}

\textbf{Storage Management:}

\begin{itemize}
\item File system implementation
\item Directory structures
\item File permissions and security
\item Disk block allocation
\end{itemize}

\textbf{Input/Output Handling:}

\begin{itemize}
\item Device drivers
\item Interrupt handling
\item Buffering and caching
\item Asynchronous I/O
\end{itemize}

\textbf{Task Scheduling:}

\begin{itemize}
\item Process scheduling algorithms
\item Thread scheduling
\item Priority management
\item Time-slicing and preemption
\end{itemize}

\textbf{Resource Sharing:}

\begin{itemize}
\item Prevents conflicts between programs
\item Enforces isolation
\item Provides controlled sharing mechanisms
\end{itemize}

\textbf{Why Operating System Needed:}

\textbf{Trust and Security:}

\begin{itemize}
\item \textbf{Cannot trust application software}
\item Programs can be malicious or buggy
\item Programs don't consider other programs
\item Need supervision and enforcement
\end{itemize}

\textbf{Coordination and Protection:}

\begin{itemize}
\item Prevents programs from breaking hardware
\item Enforces rules set by hardware (privileged instructions)
\item Provides abstraction hiding hardware details
\item Mediates access to shared resources
\end{itemize}

\textbf{Programmer Benefits:}

\textbf{Abstractions Provided:}

Programmers don't need to worry about:

\begin{itemize}
\item Where program code resides in physical memory
\item Where variables are stored in RAM
\item Hardware resource conflicts
\item Direct hardware access
\item Physical device characteristics
\end{itemize}

\textbf{OS Guarantees:}

\begin{itemize}
\item Safe hardware usage
\item Process isolation
\item Consistent interfaces
\item Reliable file storage
\item Network communication
\end{itemize}

\textbf{Example Services:}

\begin{itemize}
\item File I/O without knowing disk geometry
\item Memory allocation without physical addresses
\item Network communication without protocol details
\item Device I/O without hardware specifics
\end{itemize}

\subsubsection{Application Software Layer (Top)}

\textbf{User-Level Programs:}

\begin{itemize}
\item Programs written by application programmers
\item Solve specific problems or provide services
\item Interact with users
\item Implement business logic
\end{itemize}

\textbf{High-Level Programming Languages:}

\textbf{Popular Languages:}

\begin{itemize}
\item \textbf{C:} Systems programming, performance-critical
\item \textbf{Java:} Enterprise applications, portability
\item \textbf{Python:} Scripting, data science, machine learning
\item \textbf{R:} Statistical analysis, data science
\item \textbf{JavaScript:} Web development, client-side
\item \textbf{C++:} Performance with abstraction
\item \textbf{Go:} Concurrent systems, cloud services
\item \textbf{Rust:} Systems programming, memory safety
\end{itemize}

\textbf{Language Characteristics:}

\textbf{Hundreds/Thousands Available:}

\begin{itemize}
\item Each optimized for specific application domains
\item Different paradigms (imperative, functional, object-oriented)
\item Trade-offs between performance and productivity
\item Community and ecosystem considerations
\end{itemize}

\textbf{Domain Optimization:}

\begin{itemize}
\item \textbf{Machine Learning:} Python (NumPy, TensorFlow, PyTorch), R
\item \textbf{Systems Programming:} C, C++, Rust
\item \textbf{Enterprise Applications:} Java, C\#
\item \textbf{Web Development:} JavaScript, TypeScript, PHP, Ruby
\item \textbf{Scientific Computing:} Python, Julia, MATLAB, Fortran
\item \textbf{Mobile Development:} Swift, Kotlin, Java
\item \textbf{Game Development:} C++, C\#
\end{itemize}

\textbf{Level of Abstraction:}

\begin{itemize}
\item Represents algorithms and solutions to problems
\item Closest to problem domain
\item Furthest from hardware details
\item Highest productivity for programmers
\item Requires compilation/interpretation to execute
\end{itemize}

\subsection{From High-Level Code to Machine Code - The Translation Process}

\subsubsection{Example: Swap Function in C}

\textbf{Source Code:}

void swap(int v[], int k) {
  int temp;
  temp = v[k];
  v[k] = v[k+1];
  v[k+1] = temp;
}

\textbf{Function Purpose:}

\begin{itemize}
\item \textbf{Operation:} Swap two values in array
\item \textbf{Parameters:}
\item v[]: Array pointer (base address)
\item k: Index of first element to swap
\item \textbf{Elements Swapped:} Positions k and k+1
\item \textbf{Method:} Uses temporary variable
\item \textbf{Simplicity:} Basic operation used frequently in sorting algorithms
\end{itemize}

\textbf{Algorithm:}

\begin{enumerate}
\item Store v[k] in temporary variable
\item Copy v[k+1] to v[k]
\item Copy temporary to v[k+1]
\end{enumerate}

\subsubsection{After Compilation - MIPS Assembly Code}

\textbf{Assembly Translation:}

The compiler generates 7 MIPS instructions to implement the swap function:

\begin{verbatim}
MUL  $2, $5, 4      # Multiply k by 4 (array index to byte offset)
ADD  $2, $4, $2     # Add base address to offset (address of v[k])
LW   $15, 0($2)     # Load v[k] into register $15 (temp = v[k])
LW   $16, 4($2)     # Load v[k+1] into register $16
SW   $16, 0($2)     # Store v[k+1] to v[k]
SW   $15, 4($2)     # Store temp to v[k+1]
\end{verbatim}

\textbf{Translation Analysis:}

\begin{itemize}
\item \textbf{5 C statements} $\rightarrow$ \textbf{7 assembly instructions}
\item Expansion due to instruction granularity
\item Each assembly instruction is simple operation
\end{itemize}

\textbf{Key Operations Explained:}

\textbf{1. Address Calculation:}

\begin{itemize}
\item \textbf{Multiply by 4:} Each integer occupies 4 bytes in memory
\item \textbf{Index k} must be converted to \textbf{byte offset (k$\times$4)}
\item Calculate memory address of v[k]
\end{itemize}

\textbf{2. Memory Addressing:}

\begin{itemize}
\item Base address of array in register $4
\item Offset calculated and added to base
\item Results in absolute memory address
\end{itemize}

\textbf{3. Register Usage:}

\begin{itemize}
\item \textbf{$4:} Base address of array v (parameter)
\item \textbf{$5:} Value of k (parameter)
\item \textbf{$2:} Temporary register for address calculation
\item \textbf{$15:} Temporary storage for v[k] value
\item \textbf{$16:} Temporary storage for v[k+1] value
\end{itemize}

\textbf{Instruction Set Details:}

\begin{itemize}
\item \textbf{MIPS ISA} used in example (not ARM, but similar concepts)
\item Load-Store architecture
\item Register-to-register operations
\item Explicit memory addressing
\end{itemize}

\subsubsection{After Assembly - Machine Code}

\textbf{Binary Representation:}

Each assembly instruction translates to 32-bit binary instruction:

\begin{verbatim}
00000000101000100001000000011000  # MUL $2, $5, 4
00000000100000100001000000100001  # ADD $2, $4, $2
10001100010011110000000000000000  # LW  $15, 0($2)
10001100010100000000000000000100  # LW  $16, 4($2)
10101100010100000000000000000000  # SW  $16, 0($2)
10101100010011110000000000000100  # SW  $15, 4($2)
\end{verbatim}

\textbf{One-to-One Mapping:}

\begin{itemize}
\item Each assembly instruction $\rightarrow$ Exactly one 32-bit machine instruction
\item No information lost or gained
\item Deterministic translation
\item Assembly is human-readable form of machine code
\end{itemize}

\textbf{Instruction Format:}

Different instruction types have different bit field layouts:

\textbf{R-Type (Register) Format:}

[Opcode 6 bits][Rs 5 bits][Rt 5 bits][Rd 5 bits][Shamt 5 bits][Funct 6 bits]

\textbf{I-Type (Immediate) Format:}

[Opcode 6 bits][Rs 5 bits][Rt 5 bits][Immediate 16 bits]

\textbf{Instruction Components Specify:}

\begin{itemize}
\item \textbf{Opcode:} Operation category
\item \textbf{Destination Register:} Where result goes
\item \textbf{Source Registers:} Where operands come from
\item \textbf{Immediate Values:} Constant values (like 4 in multiply)
\item \textbf{Function Code:} Specific operation for R-type
\end{itemize}

\textbf{Example Analysis:}

In the immediate value 4:

\begin{itemize}
\item Appears in specific bit positions
\item Encoded in binary (00000000000100)
\item Part of instruction encoding
\end{itemize}

\textbf{Binary Image:}

\begin{itemize}
\item Complete program represented as sequence of 32-bit words
\item Called \textbf{executable} or \textbf{binary image}
\item Stored in secondary storage (hard disk, SSD)
\item Loaded into memory when program executes
\item CPU fetches and executes instructions sequentially
\end{itemize}

\subsection{Program Execution - Inside the CPU}

\subsubsection{Block Diagram of Computer}

\textbf{System Components:}

\textbf{Compiler/Tool Chain:}

\begin{itemize}
\item Translates human-written program to machine code
\item Optimization and code generation
\item Produces executable binary
\end{itemize}

\textbf{Memory:}

\begin{itemize}
\item Stores program instructions
\item Stores program data
\item Hierarchical (cache, RAM, disk)
\end{itemize}

\textbf{CPU (Central Processing Unit):}

\begin{itemize}
\item Executes machine instructions
\item Performs arithmetic and logic
\item Controls program flow
\end{itemize}

\textbf{Input/Output:}

\begin{itemize}
\item Peripherals (keyboard, display, network)
\item Storage devices (disk, SSD)
\item Communication interfaces
\end{itemize}

\textbf{Program Execution Flow:}

\textbf{1. Compile Stage:}

\begin{itemize}
\item Source code $\rightarrow$ Assembly $\rightarrow$ Machine code
\item Performed once (or when code changes)
\item Output: Executable binary file
\end{itemize}

\textbf{2. Store Stage:}

\begin{itemize}
\item Machine code saved to secondary storage
\item Persistent storage (survives power off)
\item Typically on hard disk or SSD
\end{itemize}

\textbf{3. Load Stage:}

\begin{itemize}
\item Machine code loaded into main memory (RAM) when program runs
\item Operating system performs loading
\item Program becomes "process"
\end{itemize}

\textbf{4. Execute Stage:}

\begin{itemize}
\item CPU fetches instructions from memory one by one
\item Executes each instruction in sequence (or out-of-order)
\item Updates registers and memory
\end{itemize}

\textbf{5. Results Stage:}

\begin{itemize}
\item Computed values stored back in memory
\item Output sent to I/O devices
\item Results displayed or saved
\end{itemize}

\subsubsection{Inside the CPU - Two Main Components}

\textbf{Datapath:}

\textbf{Structure:}

\begin{itemize}
\item Collection of logic circuits interconnected
\item Forms a path through CPU
\item Instruction and data travel through this path
\item Sequential stages of processing
\end{itemize}

\textbf{Components:}

\begin{itemize}
\item Functional units (adders, multipliers, shifters, logic units)
\item Registers for temporary storage
\item Multiplexers for routing
\item Buses for data transfer
\end{itemize}

\textbf{Function:}

\begin{itemize}
\item Instruction travels from one logic circuit to another
\item Each circuit performs specific operation on data
\item Transforms inputs to outputs
\item Executes the computational work
\end{itemize}

\textbf{Examples of Functional Units:}

\begin{itemize}
\item Arithmetic Logic Unit (ALU)
\item Floating-Point Unit (FPU)
\item Load-Store Unit
\item Branch Unit
\end{itemize}

\textbf{Control:}

\textbf{Structure:}

\begin{itemize}
\item Another logic circuit (or set of circuits)
\item Generates control signals
\item Coordinates datapath operation
\end{itemize}

\textbf{Function:}

\begin{itemize}
\item Governs instruction/data flow through datapath
\item Ensures instructions execute correctly
\item Selects appropriate functional units
\item Controls multiplexers and enables
\end{itemize}

\textbf{Responsibilities:}

\begin{itemize}
\item Decode instructions
\item Generate appropriate control signals
\item Coordinate timing
\item Handle exceptions and interrupts
\end{itemize}

\textbf{Interaction:}

\begin{itemize}
\item \textbf{Control} tells \textbf{Datapath} what to do
\item \textbf{Datapath} performs the actual computation
\item \textbf{Control} monitors \textbf{Datapath} status
\item Together implement instruction execution
\end{itemize}

\subsubsection{Execution Process (Conveyor Belt Analogy)}

\textbf{Instruction Execution Cycle:}

\textbf{1. Fetch:}

\begin{itemize}
\item Instructions stored in memory
\item Control fetches one instruction at a time
\item Brings instruction into CPU
\item Increments program counter
\end{itemize}

\textbf{2. Decode:}

\begin{itemize}
\item Instruction enters datapath
\item Control decodes instruction
\item Determines operation type
\item Identifies operands
\end{itemize}

\textbf{3. Execute:}

\begin{itemize}
\item Instruction travels through logic circuits in datapath
\item Operations performed on data
\item Functional units activated
\item Intermediate results produced
\end{itemize}

\textbf{4. Memory:}

\begin{itemize}
\item Memory accesses performed if needed (load/store)
\item Data read from or written to memory
\item Address calculation completed
\end{itemize}

\textbf{5. Writeback:}

\begin{itemize}
\item Results generated
\item Written back to registers
\item Results may be sent to memory or I/O
\end{itemize}

\textbf{6. Repeat:}

\begin{itemize}
\item Cycle repeats for next instruction
\item Like conveyor belt: continuous flow
\item One instruction after another (in simple model)
\end{itemize}

\textbf{Conveyor Belt Metaphor:}

\begin{itemize}
\item Instructions like items on conveyor belt
\item Each station performs specific operation
\item Continuous movement through system
\item Pipelining overlaps multiple instructions (discussed in later lectures)
\end{itemize}

\subsubsection{Cache Memory}

\textbf{Purpose and Motivation:}

\textbf{The Performance Gap:}

\begin{itemize}
\item CPU can process data very fast
\item Main memory access is relatively slow
\item Speed mismatch creates bottleneck
\item CPU would waste time waiting for memory
\end{itemize}

\textbf{Cache Solution:}

\begin{itemize}
\item Fast memory located on CPU chip
\item Very close to processor core physically
\item Stores copies of frequently used instructions and data
\item Exploits locality of reference
\end{itemize}

\textbf{Cache Hierarchy:}

\textbf{Level 1 Cache (L1):}

\begin{itemize}
\item Smallest capacity (32-64 KB)
\item Fastest access (1-2 cycles)
\item Closest to core
\item Often split: L1-I (instruction), L1-D (data)
\end{itemize}

\textbf{Level 2 Cache (L2):}

\begin{itemize}
\item Medium capacity (256 KB - 1 MB)
\item Medium access time (4-10 cycles)
\item May be per-core or shared
\item Unified (instructions and data)
\end{itemize}

\textbf{Level 3 Cache (L3):}

\begin{itemize}
\item Largest capacity (several MB)
\item Slower access (20-40 cycles)
\item Shared across all cores
\item Last level cache (LLC)
\end{itemize}

\textbf{Performance Impact:}

\begin{itemize}
\item Cache hit: Data found in cache (fast)
\item Cache miss: Must access main memory (slow)
\item Hit rate critical for performance
\item Well-designed cache can achieve >95\% hit rate
\end{itemize}

\textbf{Will Learn in Lecture:}

\begin{itemize}
\item Cache organization
\item Mapping strategies (direct-mapped, set-associative)
\item Replacement policies
\item Write policies
\item Cache coherency in multi-core
\end{itemize}

\subsection{Real CPU Layout - AMD Barcelona Example}

\subsubsection{Overview}

\textbf{AMD Barcelona Processor:}

\begin{itemize}
\item Released around 2007
\item Quad-core processor (4 cores on single die)
\item 65nm manufacturing process
\item Actual chip much smaller than magnified images
\item Can visually identify individual components
\end{itemize}

\textbf{Die Photo Analysis:}

\begin{itemize}
\item Optical or electron microscope image
\item Shows physical layout of components
\item Different functional units visible
\item Reveals organizational decisions
\item Educational value for understanding architecture
\end{itemize}

\subsubsection{Four Processor Cores}

\textbf{Core Distribution:}

Physical layout shows clear quadrant organization:

\begin{itemize}
\item \textbf{Core 1:} Upper left area of die
\item \textbf{Core 2:} Upper right area of die
\item \textbf{Core 3:} Lower left area of die
\item \textbf{Core 4:} Lower right area of die
\end{itemize}

\textbf{Layout Strategy:}

\begin{itemize}
\item \textbf{Mirror Image Layouts:} Cores identical but mirrored
\item \textbf{Symmetry:} Simplifies design and manufacturing
\item \textbf{Thermal Distribution:} Spreads heat across die
\item \textbf{Interconnect Balance:} Equal distances to shared resources
\end{itemize}

\subsubsection{Inside Each Core}

\textbf{Floating-Point Unit (FPU):}

\textbf{Characteristics:}

\begin{itemize}
\item \textbf{Large Component:} Significant silicon area in each core
\item \textbf{Complex Circuitry:} Handles IEEE 754 floating-point arithmetic
\item \textbf{High Transistor Count:} Precision requires many gates
\end{itemize}

\textbf{Operations:}

\begin{itemize}
\item Addition, subtraction of floating-point numbers
\item Multiplication of floating-point numbers
\item Division of floating-point numbers
\item Square root and other mathematical functions
\end{itemize}

\textbf{Why So Large:}

\begin{itemize}
\item Floating-point math more complex than integer
\item Requires normalization, rounding, exception handling
\item Multiple pipeline stages
\item High precision demands
\end{itemize}

\textbf{Load-Store Unit:}

\textbf{Function:}

\begin{itemize}
\item Handles all memory operations
\item Loads data from memory to CPU registers
\item Stores data from CPU registers to memory
\item Critical for data transfer
\end{itemize}

\textbf{Operations:}

\begin{itemize}
\item Address calculation
\item Cache access
\item TLB (Translation Lookaside Buffer) lookup
\item Memory ordering and consistency
\end{itemize}

\textbf{Integer Execution Unit:}

\textbf{Characteristics:}

\begin{itemize}
\item \textbf{Smaller than FPU:} Integer operations generally simpler
\item \textbf{High Frequency:} Often faster than floating-point
\end{itemize}

\textbf{Operations:}

\begin{itemize}
\item Integer arithmetic (add, subtract, multiply, divide)
\item Bitwise logical operations (AND, OR, XOR, NOT)
\item Shifts and rotates
\item Comparisons
\end{itemize}

\textbf{Why Smaller:}

\begin{itemize}
\item Simpler algorithms
\item No normalization needed
\item Exact arithmetic (no rounding)
\item Fewer pipeline stages
\end{itemize}

\textbf{Fetch and Decode Unit:}

\textbf{Responsibilities:}

\textbf{Instruction Fetch:}

\begin{itemize}
\item Fetches instructions from memory (via I-cache)
\item Predicts branch targets
\item Manages instruction buffer
\end{itemize}

\textbf{Instruction Decode:}

\begin{itemize}
\item Makes sense of binary instruction encoding
\item Determines instruction type
\item Identifies operands
\item Generates micro-ops (for CISC architectures)
\end{itemize}

\textbf{Pipeline Frontend:}

\begin{itemize}
\item Prepares instructions for execution
\item Handles instruction-level parallelism
\item Feeds execution units
\end{itemize}

\textbf{Level 1 Data Cache (L1 D-Cache):}

\textbf{Characteristics:}

\begin{itemize}
\item Stores frequently used \textbf{data} (not instructions)
\item Very fast access (1-2 cycle latency)
\item Close to execution units
\item Separate from instruction cache (Harvard architecture)
\end{itemize}

\textbf{Typical Specifications:}

\begin{itemize}
\item 32-64 KB capacity
\item 8-way set associative
\item Write-through or write-back policy
\end{itemize}

\textbf{Level 1 Instruction Cache (L1 I-Cache):}

\textbf{Characteristics:}

\begin{itemize}
\item Stores frequently used \textbf{instructions} (program code only)
\item Very fast access
\item Feeds fetch unit
\item Separate from data cache
\end{itemize}

\textbf{Benefits of Separation:}

\begin{itemize}
\item No structural hazards (simultaneous instruction fetch and data access)
\item Optimized for different access patterns
\item Simpler control logic
\end{itemize}

\textbf{Level 2 Unified Cache (L2 Cache):}

\textbf{Characteristics:}

\begin{itemize}
\item \textbf{Larger than L1:} Typically 512 KB per core in Barcelona
\item Stores \textbf{both instructions and data} (unified)
\item Further from execution units (higher latency)
\item Victim cache for L1 misses
\end{itemize}

\textbf{Architecture:}

\begin{itemize}
\item Dedicated control logic for coherency
\item Interface to L3 cache or memory
\item May use different associativity than L1
\end{itemize}

\subsubsection{Shared Components}

\textbf{North Bridge (Central Hub):}

\textbf{Location:}

\begin{itemize}
\item Central/middle area of chip
\item Strategic position for communication
\end{itemize}

\textbf{Functions:}

\begin{itemize}
\item \textbf{L2-to-Memory Connection:} Connects all L2 caches to main memory
\item \textbf{Inter-Core Communication:} Coordinates between cores
\item \textbf{Memory Controller:} May include integrated memory controller
\item \textbf{Cache Coherency:} Maintains coherency protocol between cores
\end{itemize}

\textbf{Critical Role:}

\begin{itemize}
\item Central communication circuit
\item Bandwidth bottleneck if not designed well
\item Affects multi-core scaling
\end{itemize}

\textbf{DDR PHY (Physical Controller):}

\textbf{DDR Memory:}

\begin{itemize}
\item \textbf{DDR:} Dual Data Rate SDRAM
\item Transfers data on both rising and falling clock edges
\item Industry-standard memory interface
\end{itemize}

\textbf{PHY (Physical Layer):}

\begin{itemize}
\item \textbf{PHY:} Physical layer controller
\item Interfaces CPU to DDR RAM modules
\item Handles physical signaling
\end{itemize}

\textbf{Responsibilities:}

\begin{itemize}
\item Electrical interface to memory chips
\item Signal timing and termination
\item Training and calibration
\item Error detection/correction
\end{itemize}

\textbf{HyperTransport Controllers:}

\textbf{HyperTransport Technology:}

\begin{itemize}
\item High-speed interconnect technology (AMD proprietary)
\item Point-to-point serial communication
\item Replaces legacy parallel buses
\item High bandwidth, low latency
\end{itemize}

\textbf{Connections:}

\begin{itemize}
\item \textbf{External Devices:} Graphics cards, other processors
\item \textbf{Chipset Communication:} Northbridge, southbridge links
\item \textbf{I/O Device Connectivity:} Network, storage, peripherals
\end{itemize}

\textbf{Benefits:}

\begin{itemize}
\item Scalable bandwidth
\item Lower pin count than parallel buses
\item NUMA (Non-Uniform Memory Access) support for multi-socket systems
\end{itemize}

\subsubsection{Additional Information}

\textbf{WikiChip Database:} https://en.wikichip.org

\textbf{Comprehensive Processor Information:}

\textbf{Major Manufacturers Covered:}

\begin{itemize}
\item \textbf{Intel Processors:} x86 architecture, Core series, Xeon servers
\item \textbf{AMD Processors:} x86 architecture, Ryzen, EPYC, Threadripper
\item \textbf{ARM Processors:} Mobile devices, embedded systems, servers
\item \textbf{Samsung Exynos:} Smartphones and tablets
\item \textbf{Apple A-Series:} iPhone and iPad processors
\item \textbf{Apple M-Series:} Mac computers (ARM-based)
\item \textbf{Qualcomm:} Snapdragon mobile processors
\item \textbf{NVIDIA, Broadcom, Texas Instruments, and many more}
\end{itemize}

\textbf{Available Information:}

\textbf{Visual Content:}

\begin{itemize}
\item Processor die photographs and diagrams
\item Block diagrams showing architecture
\item Cache hierarchy visualizations
\item Microarchitecture pipeline diagrams
\end{itemize}

\textbf{Technical Specifications:}

\begin{itemize}
\item Manufacturing process (nm technology)
\item Transistor counts and density
\item Transistor types and structures
\item Die size and area
\item Power consumption (TDP)
\item Clock speeds (base and turbo)
\item Core counts and threading
\item Cache sizes and organization
\end{itemize}

\textbf{Advanced Topics:}

\begin{itemize}
\item 3D stacking technology details
\item FinFET and GAA transistor structures
\item Packaging technologies
\item Memory interface specifications
\item I/O capabilities
\end{itemize}

\textbf{Current Technology Landscape (2021):}

\textbf{Mainstream Manufacturing:}

\begin{itemize}
\item \textbf{10 nm and 7 nm} processes in volume production
\item Multiple manufacturers at this node
\end{itemize}

\textbf{Future Direction:}

\begin{itemize}
\item \textbf{Next Few Years:} Shift to 5 nm and 3 nm
\item 2 nm and 1 nm in research
\end{itemize}

\textbf{Important Clarification:}

\begin{itemize}
\item \textbf{Numbers don't represent actual gate size anymore}
\item \textbf{Marketing terms} more than physical measurements
\item \textbf{Example:} 5 nm transistors may have wider channels than 10 nm
\item \textbf{Density Increase Through:}
\item 3D stacking (vertical integration)
\item FinFET and GAA structures
\item Improved layouts and design rules
\item Multi-patterning lithography
\end{itemize}

\subsection{Key Takeaways}

\begin{enumerate}
\item \textbf{Moore's Law predicted transistor doubling every 2 years} - remarkably accurate for over 40 years, guiding semiconductor industry planning and investment
\end{enumerate}

\begin{enumerate}
\item \textbf{Smaller transistors enabled by improved lithography} - progression from 90nm $\rightarrow$ 45nm $\rightarrow$ 22nm $\rightarrow$ 7nm $\rightarrow$ 5nm through advancing manufacturing processes
\end{enumerate}

\begin{enumerate}
\item \textbf{Feature size now marketing term rather than physical measurement} - modern processes use 3D structures making simple linear dimensions misleading
\end{enumerate}

\begin{enumerate}
\item \textbf{Smaller transistors provide dual benefits} - enable more complex circuits (more transistors available) and faster switching (lower voltage, reduced impedance)
\end{enumerate}

\begin{enumerate}
\item \textbf{Clock rate increased exponentially until ~2004} - grew from 12.5 MHz (1982) to 3.6 GHz (2004), then hit fundamental thermal limitations
\end{enumerate}

\begin{enumerate}
\item \textbf{Power wall halted frequency scaling} - heat generation (P = CV²f) exceeded cooling capability, establishing ~100W practical limit for consumer processors
\end{enumerate}

\begin{enumerate}
\item \textbf{Dynamic power equation explains the crisis} - despite 25$\times$ power reduction from voltage scaling, 300$\times$ frequency increase overwhelmed the benefit
\end{enumerate}

\begin{enumerate}
\item \textbf{Overclocking emerged as risky performance technique} - users could exceed rated speeds at risk of destroying processors, popular among gaming enthusiasts
\end{enumerate}

\begin{enumerate}
\item \textbf{Industry pivoted to multi-core processors} - solution to utilize Moore's Law transistors without exceeding power limits, starting ~2004-2008
\end{enumerate}

\begin{enumerate}
\item \textbf{Multi-core growth slowed due to programming difficulty} - initial projection of hundreds of cores didn't materialize; parallel programming remains challenging
\end{enumerate}

\begin{enumerate}
\item \textbf{Parallel programming requires explicit management} - unlike automatic instruction-level parallelism, multi-core requires programmers to handle threads, synchronization, communication
\end{enumerate}

\begin{enumerate}
\item \textbf{Three major parallel programming challenges} - load balancing across cores, minimizing communication overhead, optimizing synchronization
\end{enumerate}

\begin{enumerate}
\item \textbf{3D chip technology changed scaling paradigm (2013-2015)} - industry shifted from pure 2D shrinking to vertical stacking of transistor layers
\end{enumerate}

\begin{enumerate}
\item \textbf{ITRS dissolved in 2015} - technology roadmap organization ended as multiple paths to density replaced simple feature size scaling
\end{enumerate}

\begin{enumerate}
\item \textbf{Computer systems organized in three layers} - hardware (physical components), system software (OS, compilers, tools), application software (user programs)
\end{enumerate}

\begin{enumerate}
\item \textbf{System software provides abstraction and protection} - OS prevents malicious programs from damaging hardware, hides complexity from application programmers
\end{enumerate}

\begin{enumerate}
\item \textbf{Program translation is multi-stage process} - high-level language $\rightarrow$ assembly language $\rightarrow$ machine code through compiler, assembler, linker
\end{enumerate}

\begin{enumerate}
\item \textbf{CPU contains datapath and control} - datapath performs computation by routing data through functional units; control coordinates execution and generates signals
\end{enumerate}

\begin{enumerate}
\item \textbf{Cache memory critical for performance} - fast on-chip memory (L1, L2, L3) stores frequently accessed data/instructions, hiding main memory latency
\end{enumerate}

\begin{enumerate}
\item \textbf{Real CPUs have complex layouts} - die photos reveal intricate organization with multiple cores, cache hierarchies, shared interconnects, memory controllers
\end{enumerate}

\subsection{Summary}

This lecture provides a comprehensive examination of computer technology evolution from the 1970s to present day. Moore's Law, predicting transistor count doubling every two years, serves as the guiding principle for the semiconductor industry and enables the transformation of computers from room-sized machines to powerful pocket devices.

The progression of manufacturing technology steadily reduced feature sizes from 90 nanometers to current 7nm and 5nm processes. Smaller transistors provided two key advantages: more transistors per chip enabling complex functionality, and faster switching speeds enabling higher clock frequencies. Clock rates grew exponentially from 12.5 MHz in 1982 to 3.6 GHz in 2004.

However, around 2004, the industry encountered the power wall - a fundamental thermal limitation. The dynamic power equation (P = CV²f) revealed that despite aggressive voltage scaling, the massive frequency increases caused power consumption and heat generation to exceed cooling capabilities. The ~100-watt limit for consumer processors could not be overcome by improved cooling solutions.

The solution was multi-core processors: placing multiple complete CPU cores on a single chip. This allowed continued performance improvement within power constraints by exploiting thread-level parallelism. However, the initial vision of exponentially growing core counts didn't materialize due to the difficulty of parallel programming. Unlike automatic instruction-level parallelism, multi-core requires programmers to explicitly manage threads, balance loads, minimize communication, and handle synchronization - a significantly more challenging paradigm.

Around 2013-2015, the industry made another major shift to 3D chip technology. Instead of only shrinking transistors in two dimensions, manufacturers began stacking transistor layers vertically using FinFET and similar technologies. This represented such a fundamental change that the International Technology Roadmap for Semiconductors (ITRS) dissolved in 2015, as simple feature-size predictions no longer captured the diverse approaches to increasing transistor density.

The lecture concluded by examining computer system organization across three layers: hardware (processor, memory, I/O), system software (compilers, assemblers, operating system), and application software (programs written in high-level languages). We traced the complete journey from high-level code through compilation and assembly to binary machine code, and explored how programs execute through the interaction of control and datapath components within the CPU. Cache memory's critical role in hiding main memory latency was emphasized, and real-world processor layouts illustrated the complex organization of modern multi-core chips.

Understanding these technology trends and architectural responses provides essential context for studying computer architecture and explains why processors are organized as they are today.
